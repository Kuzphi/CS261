\normalfont\documentclass[letterpaper,11pt]{article}
\usepackage{amsmath, amsfonts,amssymb,latexsym}
\usepackage{fullpage}
\usepackage{parskip}
\usepackage{flexisym}
\usepackage{algorithm}
\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{pythonhighlight}
\usepackage{amsmath}
\usepackage{hyperref}
\begin{document}
\setlength{\parindent}{2ex}
\newcommand{\header}{
	\noindent \fbox{
	\begin{minipage}{6.4in}
  	\medskip
  	\textbf{CS 261 - Data Structure} \hfill \textbf{Spring 2017} \\[1mm]
  	\begin{center}
    	{\Large HomeWork 4} \\[3mm]
  	\end{center}
	\today \hfill \itshape{Liangjian Chen}
	\medskip
	\end{minipage}}
}
\newcommand{\RN}[1]{%
  \textup{\uppercase\expandafter{\romannumeral#1}}%
}
4
\bigskip
\header

\begin{enumerate}
\item [Problem 1]\textbf{Solution:}\par
\begin{enumerate}
	\item for any new incoming $x_i$, $p \leftarrow p + x_i, q \leftarrow q + x_i^2$
	\item average:$\frac{p}{n}$\par
	standard deviation:
	\begin{flalign*}
	&\sqrt{\frac{1}{n}\sum_{i=1}^n(x_i-\bar{x_i})^2}&\\
	&= \sqrt{\frac{1}{n}\sum_{i=1}^n x_i^2 - 2 x_i * \bar{x_i}+\bar{x}^2}\\
	&= \sqrt{\frac{1}{n}(\sum_{i=1}^n x_i^2 - 2\bar{x} \sum_{i=1}^n x_i + \sum_{i=1}^n \bar{x}^2)}\\
	&\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i
	\end{flalign*}
	By the previous soultion, we can maintain the $\sum_{i=1}^n x_i^2$ and $\sum_{i=1}^n x_i$. Thus by using the formula shown above, standard deviation can be maintained as well.
\end{enumerate}	
\item [Problem 2]\textbf{Solution:}\par
	assume $|A| = |B| = t$
	\begin{flalign*}
	&\frac{|A\cap B|}{\sqrt{|A| * |B|}}&\\
	&= \frac{|A\cap B|}{t} \\
	&= x\\
	&\rightarrow |A\cap B| = tx\\ \\
	&\frac{|A\cap B|}{|A\cup B|}\\
	&=\frac{tx}{2t - tx}\\
	&=\frac{x}{2-x}
	\end{flalign*}
\item [Problem 3]\textbf{Solution:}\par
AAABBBBCC\par
Algorithm would return C which appear the least time in the sequence.
\item [Problem 4]\textbf{Solution:}\par
I would choose the minHash. My algorithm would consider all left key as one set$L$, and all right key as one set$R$. Then our target is to estimate the size of the union $|L \cap R|$. Then we can applied minHash algorithm.\par
estimated Bound:
\begin{flalign*}
	&J(L,R) = \frac{|L \cap R|}{2n - |L \cap R|}&\\
	&\text{assume $p$ is $J(L,R)$ and $\tilde{p}$ is the estimation of $p$}\\
	&|L \cap R| = \frac{2np}{1 + p}\\
	& \text{ which indicate the following:}\\
	& (1 + \epsilon)\frac{2np}{1 + p} > \frac{2n\tilde{p}}{1 + \tilde{p}}\\
	& \tilde{p} \le \frac{p(1 + \epsilon)}{1 - p\epsilon} \le p(1 + \frac{2\epsilon}{1 - \epsilon})\\
	&\text{assume $\theta = \frac{2\epsilon}{1 - \epsilon}$, and according to \textbf{Multiplicative Chernoff Bound}, we know that:}\\
	&Pr(\tilde{p} \ge p(1 + \theta)) \le e^{-\frac{\theta^2p}{3}}\\
	&\text{which indicate that}\\
	&Pr(\tilde{p} \le p(1 + \theta)) \ge 1 - e^{-\frac{\theta^2p}{3}} = 1 - \delta(\delta = e^{-\frac{\theta^2p}{3}})
\end{flalign*}
Thus, we would have at least $1 - e^{-\frac{4\epsilon^2p}{3(1-\epsilon)^2}}$ probability to get $1 + \epsilon$ factor of accurate number.\par

\textbf{Multiplicative Chernoff Bound} from \href{https://en.wikipedia.org/wiki/Chernoff_bound}{\textbf{Wikipedia}}\par
Suppose $X_1$, ..., $X_n$ are independent random variables taking values in $\{0, 1\}$. Let $X$ denote their sum and let $\mu = E[X]$ denote the sum's expected value. Then for any $\sigma > 0$,
$$Pr(X \ge (1 + \sigma)\mu) \le e^{-\frac{\sigma^2\mu}{3}} (0 < \sigma < 1)$$
\end{enumerate}
\end{document}
